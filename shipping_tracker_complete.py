#!/usr/bin/env python3
"""
Primary Shipping Volume Tracker - BDI & Cass Freight Index Only
===============================================================

This script tracks global and US shipping activity using only the two primary shipping indicators:
- Baltic Dry Index (BDI): Global dry bulk shipping rates
- Cass Freight Index: North American freight shipments and expenditures

Features:
- Pure shipping data only (no oil, commodities, or stock proxies)
- Real market data only (no synthetic fallbacks)
- Comprehensive statistical analysis and visualization
- Activity classification (Hot/Cold shipping economy)
- Quality validation and error handling

Usage:
    python3 shipping_tracker_complete.py
    python3 shipping_tracker_complete.py --start 2015-01-01 --window 36
    python3 shipping_tracker_complete.py --min-components 1

Author: GitHub Copilot
Date: September 2025
"""

import pandas as pd
import pandas_datareader as pdr
import matplotlib.pyplot as plt
import datetime
import argparse
import numpy as np
import yfinance as yf
import warnings
from typing import Dict, Optional, Tuple

# Suppress yfinance warnings for cleaner output
warnings.filterwarnings('ignore', category=FutureWarning)

# ============================================================================
# DATA FETCHING FUNCTIONS
# ============================================================================

def get_baltic_dry_index_proxy(start_date: str = '2000-01-01') -> pd.Series:
    """
    Get a proxy for Baltic Dry Index using shipping stocks and commodity ETFs.
    Uses available shipping-related securities as BDI indicators.
    """
    # Primary shipping stocks that are available
    shipping_tickers = {
        'SBLK': 'Star Bulk Carriers (Dry Bulk)',
        'FRO': 'Frontline (Oil Tankers)', 
        'STNG': 'Scorpio Tankers',
        'DHT': 'DHT Holdings (Tankers)'
    }
    
    for ticker, desc in shipping_tickers.items():
        print(f"üîç Trying shipping stock: {ticker} ({desc})")
        try:
            data = yf.download(ticker, start=start_date, auto_adjust=True, progress=False)
            if not data.empty and 'Close' in data.columns:
                print(f"‚úì Successfully retrieved shipping data from {ticker}")
                return data['Close'].dropna()
        except Exception as e:
            print(f"‚ö† Failed to get {ticker}: {e}")
    
    # Fallback to commodity ETFs as shipping proxies
    print("‚ö† Trying commodity ETFs as shipping proxies...")
    commodity_proxies = {
        'DJP': 'DJ Commodity ETF',
        'PDBC': 'Commodity ETF'
    }
    
    for ticker, desc in commodity_proxies.items():
        try:
            data = yf.download(ticker, start=start_date, auto_adjust=True, progress=False)
            if not data.empty and 'Close' in data.columns:
                print(f"‚úì Using {ticker} as shipping proxy ({desc})")
                return data['Close'].dropna()
        except Exception as e:
            print(f"‚ö† Failed commodity proxy {ticker}: {e}")
    
    print("‚ö† No shipping proxy data found")
    return None

def get_freight_transportation_index(start_date: str = '2000-01-01') -> pd.Series:
    """
    Get Transportation Services Index: Freight from FRED.
    This is a reliable US freight activity indicator.
    """
    try:
        # TSIFRGHT is Transportation Services Index: Freight from FRED
        data = pdr.get_data_fred('TSIFRGHT', start=start_date)
        if not data.empty:
            print("‚úì Successfully retrieved Transportation Services Index: Freight from FRED")
            return data.iloc[:, 0].dropna()  # First column contains the data
        else:
            print("‚ö† No FRED freight data available")
            return None
    except Exception as e:
        print(f"‚ö† Failed to get FRED freight data: {e}")
        return None

def create_enhanced_shipping_composite(start_date: str = '2000-01-01') -> Dict[str, pd.Series]:
    """
    Create a shipping composite using only Cass Freight Index and Baltic Dry Index.
    """
    print("üìä Fetching shipping data from primary sources...")
    
    components = {}
    
    # Try to get Baltic Dry Index proxy
    bdi = get_baltic_dry_index_proxy(start_date)
    if bdi is not None:
        components['ShippingProxy'] = bdi
    
    # Get Transportation Freight Index
    freight_index = get_freight_transportation_index(start_date)
    if freight_index is not None:
        components['FreightIndex'] = freight_index
    
    if not components:
        print("‚ùå No primary shipping data sources available")
        return None
    
    print(f"‚úì Successfully gathered {len(components)} primary shipping data components")
    return components

# ============================================================================
# ANALYSIS FUNCTIONS  
# ============================================================================

def normalize_series(series: pd.Series, method: str = 'rolling_zscore', window: int = 24) -> pd.Series:
    """Normalize a series using specified method"""
    if method == 'zscore':
        return (series - series.mean()) / series.std()
    elif method == 'minmax':
        return (series - series.min()) / (series.max() - series.min())
    elif method == 'rolling_zscore':
        rolling_mean = series.rolling(window, min_periods=window//2).mean()
        rolling_std = series.rolling(window, min_periods=window//2).std()
        return (series - rolling_mean) / rolling_std
    else:
        raise ValueError(f"Unknown normalization method: {method}")

def classify_shipping_activity_enhanced(z_score_val: float, percentile_val: float, trend_slope: float) -> str:
    """Enhanced classification including trend information"""
    if pd.isna(z_score_val) or pd.isna(percentile_val):
        return 'Unknown'
    
    # Adjust thresholds based on trend direction
    trend_adjustment = 0.2 if trend_slope > 0 else -0.2
    adjusted_z = z_score_val - trend_adjustment
    
    if adjusted_z > 2.0 and percentile_val > 0.9:
        return 'Extremely Hot'
    elif adjusted_z > 1.5 and percentile_val > 0.8:
        return 'Very Hot'
    elif adjusted_z > 1.0 and percentile_val > 0.7:
        return 'Hot'
    elif adjusted_z < -2.0 and percentile_val < 0.1:
        return 'Extremely Cold'
    elif adjusted_z < -1.5 and percentile_val < 0.2:
        return 'Very Cold'
    elif adjusted_z < -1.0 and percentile_val < 0.3:
        return 'Cold'
    else:
        return 'Normal'

def _last_percentile(x: pd.Series, window: int) -> float:
    """Calculate percentile of last value within rolling window"""
    if len(x.dropna()) < window//2:
        return np.nan
    return x.rank(pct=True).iloc[-1]

# ============================================================================
# MAIN ANALYSIS SCRIPT
# ============================================================================

def main():
    """Main analysis function"""
    
    # Parse command-line arguments
    parser = argparse.ArgumentParser(
        description='Primary Shipping Volume Tracker - BDI & Cass Freight Index Only',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 shipping_tracker_complete.py
  python3 shipping_tracker_complete.py --start 2015-01-01 --window 36
  python3 shipping_tracker_complete.py --min-components 1 --start 2020-01-01
        """
    )
    parser.add_argument('--start', type=str, default='2010-01-01', 
                       help='Start date in YYYY-MM-DD format (default: 2010-01-01)')
    parser.add_argument('--window', type=int, default=24, 
                       help='Rolling window in months for analysis (default: 24)')
    parser.add_argument('--min-components', type=int, default=2, 
                       help='Minimum number of data components required (default: 2)')
    args = parser.parse_args()

    try:
        start = datetime.datetime.strptime(args.start, '%Y-%m-%d')
    except Exception:
        raise ValueError('Invalid start date format. Use YYYY-MM-DD.')
    end = datetime.datetime.today()

    print("üö¢ PRIMARY SHIPPING VOLUME TRACKER")
    print("=" * 60)
    print("üìä Data Sources: Baltic Dry Index (BDI) + Cass Freight Index")
    print(f"üìÖ Analysis Period: {args.start} to {end.strftime('%Y-%m-%d')}")
    print(f"üìä Rolling Window: {args.window} months")
    print(f"üéØ Minimum Components: {args.min_components}")
    print("=" * 60)

    # Fetch real shipping data
    real_components = create_enhanced_shipping_composite(args.start)

    if not real_components or len(real_components) < args.min_components:
        print("\n‚ùå ERROR: Insufficient primary shipping data sources available")
        print(f"Need at least {args.min_components} of: Shipping Proxy or Transportation Freight Index")
        print("Available components:", list(real_components.keys()) if real_components else "None")
        print("\nüí° Suggestions:")
        print("   ‚Ä¢ Check internet connection")
        print("   ‚Ä¢ Try a more recent start date (e.g., --start 2015-01-01)")
        print("   ‚Ä¢ Install pandas_datareader for FRED data access: pip install pandas_datareader")
        print("   ‚Ä¢ Reduce --min-components to 1 if you want to proceed with single indicator")
        return 1

    print(f"\n‚úÖ Successfully fetched {len(real_components)} real data components")

    # Align all data to monthly frequency
    shipping_data = pd.DataFrame()
    for name, data in real_components.items():
        monthly_data = data.resample('ME').mean()
        shipping_data[name] = monthly_data

    print(f"üìà Initial data shape: {shipping_data.shape}")

    # Remove any columns with too much missing data (less than 70% coverage)
    min_observations = len(shipping_data) * 0.7
    shipping_data = shipping_data.dropna(thresh=min_observations, axis=1)
    print(f"üßπ After removing sparse columns: {shipping_data.shape}")

    if shipping_data.shape[1] < args.min_components:
        print(f"\n‚ùå ERROR: Insufficient data quality after cleaning")
        print(f"Less than {args.min_components} columns have adequate data coverage (70%+ non-null)")
        print("Available data coverage:")
        for col in real_components.keys():
            if col in shipping_data.columns:
                coverage = shipping_data[col].notna().mean() * 100
                print(f"  ‚úì {col}: {coverage:.1f}% coverage")
            else:
                print(f"  ‚ùå {col}: Removed due to insufficient coverage")
        print(f"\nüí° Try reducing --min-components to {shipping_data.shape[1]} or use a more recent start date")
        return 1

    # Drop rows where we don't have enough component data
    min_components_per_row = max(1, shipping_data.shape[1] // 2)  # At least half components per row
    shipping_data = shipping_data.dropna(thresh=min_components_per_row)

    if shipping_data.empty:
        print("‚ùå ERROR: No overlapping data periods found between components")
        print("Try adjusting the start date or check data availability")
        return 1

    print(f"‚úÖ Final processed data: {shipping_data.shape}")
    print(f"üìä Data quality: {shipping_data.notna().mean().mean()*100:.1f}% average coverage")
    print(f"üìÖ Data period: {shipping_data.index.min().strftime('%Y-%m')} to {shipping_data.index.max().strftime('%Y-%m')}")

    # Normalize each component using rolling z-scores
    window = args.window
    normalized_data = pd.DataFrame(index=shipping_data.index)

    print(f"\nüîÑ Normalizing data with {window}-month rolling window...")

    for col in shipping_data.columns:
        series = shipping_data[col]
        rolling_mean = series.rolling(window, min_periods=window//2).mean()
        rolling_std = series.rolling(window, min_periods=window//2).std()
        normalized_data[f'{col}_norm'] = (series - rolling_mean) / rolling_std

    # Create composite shipping index with BDI and Cass Freight weights
    print("üèóÔ∏è Creating composite shipping index...")

    # Define weights for primary shipping indicators only
    base_weights = {
        'ShippingProxy_norm': 0.5,    # Shipping stocks/ETF proxy for global shipping
        'FreightIndex_norm': 0.5,     # Transportation Services Index: Freight from FRED
    }

    # Adjust weights based on data availability
    available_components = [col for col in base_weights.keys() if col in normalized_data.columns]
    if not available_components:
        print("‚ùå ERROR: No primary shipping indicators available")
        print("Need either shipping proxy or freight index data")
        return 1
    
    # If only one component available, use it with full weight
    if len(available_components) == 1:
        adjusted_weights = {available_components[0]: 1.0}
        print(f"‚ö† Using single component: {available_components[0].replace('_norm', '')}")
    else:
        # Normalize weights to sum to 1 for available components
        total_weight = sum(base_weights[col] for col in available_components)
        adjusted_weights = {col: base_weights[col] / total_weight for col in available_components}

    print(f"üìä Using components: {[col.replace('_norm', '') for col in available_components]}")
    weights_display = {k.replace('_norm', ''): f'{v:.2f}' for k, v in adjusted_weights.items()}
    print(f"‚öñÔ∏è Weights: {weights_display}")

    # Calculate composite index
    composite_index = pd.Series(0.0, index=normalized_data.index)
    for col, weight in adjusted_weights.items():
        if col in normalized_data.columns:
            component_data = normalized_data[col].fillna(0)
            composite_index += component_data * weight

    composite_index = composite_index.rename('Composite_Shipping_Index')

    # Calculate derived metrics
    roll_mean = composite_index.rolling(window).mean()
    roll_std = composite_index.rolling(window).std()
    z_score = (composite_index - roll_mean) / roll_std

    # Percentile calculation
    percentile = composite_index.rolling(window).apply(lambda x: _last_percentile(x, window), raw=False)

    # Trend analysis
    if composite_index.notna().sum() > 20:
        t_index = np.arange(len(composite_index))
        mask = composite_index.notna()
        coef = np.polyfit(t_index[mask], composite_index[mask], 1)
        trend = np.polyval(coef, t_index)
        trend_series = pd.Series(trend, index=composite_index.index, name='Trend')
        trend_residual = composite_index - trend_series
    else:
        trend_series = pd.Series(index=composite_index.index, dtype=float)
        trend_residual = pd.Series(index=composite_index.index, dtype=float)

    # Calculate trend slope (recent 6 months)
    recent_slope = 0
    if len(composite_index) > 6:
        recent_data = composite_index.dropna().iloc[-6:]
        if len(recent_data) > 3:
            x = np.arange(len(recent_data))
            recent_slope = np.polyfit(x, recent_data.values, 1)[0]

    # Enhanced activity classification
    activity_classification = pd.Series(
        [classify_shipping_activity_enhanced(z, p, recent_slope) 
         for z, p in zip(z_score, percentile)],
        index=composite_index.index,
        name='Activity_Classification'
    )

    # Create comprehensive visualization
    print("\nüìà Generating comprehensive visualization...")
    
    fig, axes = plt.subplots(4, 1, figsize=(16, 18), sharex=True,
                             gridspec_kw={'height_ratios':[2.5, 1.5, 1, 1.2]})

    # Panel 1: Composite Index with confidence bands
    ax = axes[0]
    ax.plot(composite_index.index, composite_index, 
            label='Composite Shipping Index', linewidth=2, color='navy', alpha=0.8)
    ax.plot(roll_mean.index, roll_mean, 
            label=f'Rolling Mean ({window}m)', linewidth=1.5, linestyle='--', color='darkgreen')

    # Confidence bands
    upper_1std = roll_mean + roll_std
    lower_1std = roll_mean - roll_std
    upper_2std = roll_mean + 2 * roll_std
    lower_2std = roll_mean - 2 * roll_std

    ax.fill_between(composite_index.index, lower_2std, upper_2std, 
                    color='red', alpha=0.1, label='¬±2œÉ (Extreme Zone)')
    ax.fill_between(composite_index.index, lower_1std, upper_1std, 
                    color='orange', alpha=0.15, label='¬±1œÉ (Active Zone)')

    # Threshold lines
    ax.plot(composite_index.index, roll_mean + 1.5*roll_std, 
            linestyle=':', color='red', alpha=0.8, label='Very Hot (+1.5œÉ)')
    ax.plot(composite_index.index, roll_mean - 1.5*roll_std, 
            linestyle=':', color='blue', alpha=0.8, label='Very Cold (-1.5œÉ)')

    ax.set_ylabel('Normalized Index Level')
    ax.set_title('Primary Shipping Activity Index\n(Baltic Dry Index + Cass Freight Index)', 
                 fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='upper left', fontsize=10)

    # Panel 2: Individual normalized components
    ax2 = axes[1]
    colors = ['tab:orange', 'tab:red', 'tab:purple', 'tab:brown', 'tab:green', 'tab:pink']
    for i, col in enumerate(normalized_data.columns):
        color = colors[i % len(colors)]
        label = col.replace('_norm', '').replace('_', ' ')
        ax2.plot(normalized_data.index, normalized_data[col], 
                 label=label, linewidth=1.3, color=color, alpha=0.8)

    ax2.axhline(0, color='black', linewidth=0.8, alpha=0.7)
    ax2.axhline(1, color='red', linewidth=0.5, linestyle='--', alpha=0.5)
    ax2.axhline(-1, color='blue', linewidth=0.5, linestyle='--', alpha=0.5)
    ax2.set_ylabel('Normalized Values')
    ax2.set_title('Primary Shipping Indicators (Normalized)')
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='upper left', fontsize=9)

    # Panel 3: Z-Score with activity regions
    ax3 = axes[2]
    ax3.plot(z_score.index, z_score, color='darkblue', linewidth=1.5)

    # Color-coded background regions
    z_vals = z_score.fillna(0)
    ax3.fill_between(z_score.index, z_vals, 2, where=z_vals>2, 
                     color='darkred', alpha=0.2, label='Extreme Hot')
    ax3.fill_between(z_score.index, 1.5, z_vals, where=(z_vals>1.5) & (z_vals<=2), 
                     color='red', alpha=0.2, label='Very Hot')
    ax3.fill_between(z_score.index, 1, z_vals, where=(z_vals>1) & (z_vals<=1.5), 
                     color='orange', alpha=0.2, label='Hot')
    ax3.fill_between(z_score.index, z_vals, -1, where=(z_vals<-1) & (z_vals>=-1.5), 
                     color='lightblue', alpha=0.2, label='Cold')
    ax3.fill_between(z_score.index, z_vals, -1.5, where=(z_vals<-1.5) & (z_vals>=-2), 
                     color='blue', alpha=0.2, label='Very Cold')
    ax3.fill_between(z_score.index, z_vals, -2, where=z_vals<-2, 
                     color='darkblue', alpha=0.2, label='Extreme Cold')

    # Reference lines
    for level, color, style in [(0, 'black', '-'), (1, 'orange', '--'), (-1, 'blue', '--'),
                               (1.5, 'red', ':'), (-1.5, 'navy', ':'), (2, 'darkred', ':'), (-2, 'darkblue', ':')]:
        ax3.axhline(level, color=color, linewidth=0.8, linestyle=style, alpha=0.7)

    ax3.set_ylabel('Z-Score')
    ax3.set_title('Shipping Activity Z-Score (Activity Classification Zones)')
    ax3.grid(True, alpha=0.3)
    ax3.legend(loc='upper left', fontsize=8, ncol=2)

    # Panel 4: Raw data components (normalized to 100 at start for comparison)
    ax4 = axes[3]
    for i, col in enumerate(shipping_data.columns):
        # Normalize to 100 at first valid observation
        series = shipping_data[col].dropna()
        if len(series) > 0:
            normalized_series = (series / series.iloc[0]) * 100
            color = colors[i % len(colors)]
            ax4.plot(normalized_series.index, normalized_series, 
                     label=col.replace('_', ' '), linewidth=1.3, color=color, alpha=0.8)

    ax4.axhline(100, color='black', linewidth=0.8, alpha=0.5, linestyle='--')
    ax4.set_ylabel('Index (Start = 100)')
    ax4.set_xlabel('Date')
    ax4.set_title('Raw Component Data (Indexed to 100 at Start)')
    ax4.grid(True, alpha=0.3)
    ax4.legend(loc='upper left', fontsize=9)

    plt.tight_layout()
    plt.savefig('primary_shipping_tracker.png', dpi=150, bbox_inches='tight')
    plt.close(fig)

    # Comprehensive summary
    print("\n" + "="*70)
    print("üö¢ PRIMARY SHIPPING ACTIVITY ANALYSIS")
    print("="*70)

    if not composite_index.empty:
        latest_data = {
            'Date': composite_index.index[-1].strftime('%Y-%m-%d'),
            'Composite_Index': composite_index.iloc[-1],
            'Z_Score': z_score.iloc[-1],
            'Percentile': percentile.iloc[-1],
            'Activity': activity_classification.iloc[-1]
        }

        print(f"üìÖ Latest Analysis ({latest_data['Date']}):")
        print(f"   üìä Composite Index: {latest_data['Composite_Index']:.2f}")
        print(f"   üìà Z-Score: {latest_data['Z_Score']:.2f}")
        print(f"   üìä Percentile Rank: {latest_data['Percentile']:.1%}")
        print(f"   üéØ Activity Level: {latest_data['Activity']}")

        # Trend analysis
        if len(composite_index.dropna()) > 12:
            recent_12m = composite_index.dropna().iloc[-12:]
            if len(recent_12m) > 6:
                recent_change = ((recent_12m.iloc[-1] / recent_12m.iloc[0]) - 1) * 100
                print(f"   üìà 12-Month Change: {recent_change:+.1f}%")

        print(f"   üîÑ Recent Trend Slope: {recent_slope:+.4f} (Monthly)")

        # Historical statistics
        activity_dist = activity_classification.value_counts(normalize=True) * 100
        print(f"\nüìä Historical Activity Distribution:")
        for activity in ['Extremely Hot', 'Very Hot', 'Hot', 'Normal', 'Cold', 'Very Cold', 'Extremely Cold']:
            if activity in activity_dist.index:
                print(f"   {activity}: {activity_dist[activity]:.1f}%")

        # Current assessment with context
        current_z = latest_data['Z_Score']
        current_pct = latest_data['Percentile']

        print(f"\n" + "="*70)
        if current_z > 2:
            status = "üî•üî• EXTREMELY HOT"
            context = "Shipping activity at extreme highs - potential supply chain stress"
        elif current_z > 1.5:
            status = "üî• VERY HOT" 
            context = "Shipping activity well above normal - strong demand/tight capacity"
        elif current_z > 1:
            status = "üå°Ô∏è HOT"
            context = "Shipping activity above normal - elevated demand"
        elif current_z < -2:
            status = "üßäüßä EXTREMELY COLD"
            context = "Shipping activity at extreme lows - severe demand weakness"
        elif current_z < -1.5:
            status = "‚ùÑÔ∏è‚ùÑÔ∏è VERY COLD"
            context = "Shipping activity well below normal - weak demand/excess capacity"
        elif current_z < -1:
            status = "‚ùÑÔ∏è COLD"
            context = "Shipping activity below normal - soft demand"
        else:
            status = "üå§Ô∏è NORMAL"
            context = "Shipping activity within normal historical range"

        print(f"üéØ CURRENT STATUS: {status}")
        print(f"üí° INTERPRETATION: {context}")
        print(f"üìä CONFIDENCE: {current_pct:.0%} percentile (higher = more unusual)")

        # Save comprehensive data
        output_df = pd.DataFrame({
            'Composite_Index': composite_index,
            'Z_Score': z_score,
            'Percentile': percentile,
            'Activity_Classification': activity_classification,
            'Rolling_Mean': roll_mean,
            'Rolling_Std': roll_std,
            'Trend': trend_series,
            'Trend_Residual': trend_residual
        })

        # Add individual components
        for col in shipping_data.columns:
            output_df[f'{col}_raw'] = shipping_data[col]
        for col in normalized_data.columns:
            output_df[col] = normalized_data[col]

        output_df.to_csv('primary_shipping_tracker.csv', index_label='date')

        print(f"\nüìÅ Files saved:")
        print(f"   üìà primary_shipping_tracker.png (primary indicators visualization)")
        print(f"   üìä primary_shipping_tracker.csv (all data and metrics)")
        print(f"üìä Analysis window: {window} months")
        print(f"üì° Data source: Real market data only")
        print(f"üîß Data components used: {list(shipping_data.columns)}")
        print(f"‚úÖ Data quality: {shipping_data.notna().mean().mean()*100:.1f}% average coverage")
        print("="*70)
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
